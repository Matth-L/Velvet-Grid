input {
  kafka {
    bootstrap_servers => "broker:29092"

    topics => [
     "metrics"
    ]
    group_id => "logstash"
    auto_offset_reset => "latest"
    consumer_threads => 1
    codec => "json"
  }
}


filter {
  # flattening the data
  ruby {
    code => "
      event.get('labels').each do |key, value|
        event.set(key, value)
      end
    "
  }

  # using a regex to remove the port for the instance
  grok {
    match => {
        "instance" => "^(?<instance>[^:]+)(?::\d+)?$"
    }
    overwrite => ["instance"]
  }


  # we do not want cgroup data related to the slurm daemon, only the user, so we filter the data here
  if [name] =~ /^cgroup_/ {
    ruby {
      code => '
        cgroup_val = event.get("cgroup").to_s
        # Match: system.slice/slurmstepd.scope/job_<n>/step_<n>/user/<something>
        # task_special is related to slurm daemon also, so we do not need it for profiling
        pattern = /^system\.slice\/slurmstepd\.scope\/job_(\d+)\/step_\d+\/user\/(?!task_special$).+$/
        match = cgroup_val.match(pattern)

        if match
          # extract job id from job_<n>
          event.set("job_id_slurm", match[1])
        else
          event.cancel
        end
      '
    }
  }

  if [name] == "slurm_user_node_active" {
    mutate {
      add_field => { "job_id_slurm" => "%{value}" }
      convert   => { "job_id_slurm" => "integer" }
    }
  }

  # remove useless field + convert to number value and instid
  mutate {
    remove_field => ["event","[event][original]", "timestamp", "__name__", "labels"]
    convert => {
    "instid" => "integer"
    "value" => "float"
    "job_id_slurm" => "integer"
    }
  }

}

output {
  opensearch {
    hosts => ["https://opensearch-node1:9200"]
    index => "prometheus-metrics"
    user => "admin"
    password => "SecureP@ssword1"
    ssl => true
    ssl_certificate_verification => false  # it's a demo
  }
}
